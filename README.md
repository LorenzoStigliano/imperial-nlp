# Natural Language Processing
Foundations, building blocks and applications of Natural Language Processing (NLP), with an emphasis on approaches based on deep learning.
Use these representations to study classification tasks (e.g. sentiment analysis) and tagging tasks (e.g. part of speech tagging). View languages as sequences of variable length, from pure language models to machine translation models. See approaches that are based on modern neural machine learning algorithms, where linguistic information is provided by instances of uses of language.

# Coursework

The task is to build a binary classification model
to predict whether a text contains patronising or
condescending language (PCL) using a pre-trained model, BERT. PCL is defined as
language that expresses “superior attitude towards
others or depicts them in a compassionate way.”
(P´erez-Almendros et al., 2020). Detecting PCL in
text is a challenging task for natural language processing
(NLP) models due to the fact that PLC is
usually subtle and difficult to detect, resulting in a
difficult challenge for language models.
To address this challenge, we utilize an annotated
dataset created in the paper “Don’t Patronize
Me! Patronizing and Condescending Language
Towards Vulnerable Communities” (P´erez-
Almendros et al., 2020). The dataset aimed at supporting
the development of NLP models to identify
and categorize PCL language towards vulnerable
communities. 

# Notes

| Week | Topics                 | Notes                                | Lecture Notes                                              | Papers                         |
| ---- | ---------------------- | ------------------------------------ | ---------------------------------------------------------- | ------------------------------ |
| 2    | Intro                  | [[Week 2 - 01]]                      | [[Slides - Module 1.1 - Introduction.pdf]]                 |                                |
|      | Word Representations   | [[Week 2 - 02]]                      | [[Slides - Module 1.2 - Word Representations.pdf]]         |                                |
| 3    | Classification         | [[Week 3 - 01]]                      | [[Classification - lecture 1.pdf]]                         | [[CNN_Sentence_sentiment.pdf]] |
| 4    | Language Models        | [[Week 4 - 01]]                      | [[Language Modelling - lecture 1.pdf.pdf]]                 |                                |
|      |                        | [[Week 4 - 02]]                      | [[Slides - Module 3.1 - Language Modelling lecture 2.pdf]] |                                |
| 5    | Machine Translation    | [[Week 5 - 01]]                      | [[Slides - Module 4 - Machine Translation.pdf.pdf]]        |                                |
|      |                        | [[Week 5 - 02]]                      |                                                            |                                |
| 6    | Transformers           | [[Week 6 - 01]]                      | [[Slides - Module 5 - Transformers.pdf.pdf]]               |                                |
|      |                        | [[Week 6 - Transformers Decoder]]    |                                                            |                                |
| 7    | Pre-training models    | [[Week 7 - Pre-training models]]     | [[Lecture 6.1 - Pre-training models.pdf]]                  |                                |
|      |                        | [[Week 7 - Pre training models (2)]] | [[Lecture 6.2 - Pre-training models.pdf]]                  |                                |
| 8    | Part-of-Speech tagging | [[Week 8 - Part of Speech Tagging]]  | [[2023-02 Nuri Lecture 9 - PoS Tagging.pdf]]               |                                |
|      | Constituency Parsing   | [[Week 8 - Constituency parsing]]    | [[2023-02 Nuri Lecture 10 - Constituency Parsing.pdf]]     |                                |
|      | Dependency parsing     | [[Week 8 - Dependency parsing]]      | [[2023-02 Nuri Lecture 11 - Dependency Parsing.pdf]]                                                           |                                |
